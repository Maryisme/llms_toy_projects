{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a628125f-0bcd-4d0a-a481-4358fe9f032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Imports\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Importing necessary libraries for environment management, API interactions, \n",
    "# and UI creation.\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "125955b5-9377-4cdc-9404-9f35e339c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Initialization\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Loading environment variables (including the OpenAI API key).\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Retrieve the OpenAI API key from environment variables.\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Set the OpenAI model name. This is a custom name \"gpt-4o-mini\" in this example.\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "# Create an instance of the OpenAI client.\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f1aa80-9806-49c3-8755-8238dd18997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# System Message Setup\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Defining a system message for the AI assistant, \"FlightAI.\" \n",
    "# The assistant should provide short, courteous, and accurate answers.\n",
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f487ef0-3beb-4926-b9bc-7bcb1150179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Ticket Price Retrieval Function\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# We have a dictionary that maps various destination cities to a ticket price.\n",
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    \"\"\"\n",
    "    Retrieves the price for a return ticket to a specified city.\n",
    "\n",
    "    Args:\n",
    "        destination_city (str): The city the customer wants to travel to.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - (str) The ticket price for the destination city (or 'Unknown' if not found).\n",
    "            - (str) A formatted response string indicating the price.\n",
    "    \"\"\"\n",
    "    # Print a log to indicate this function is called with the given city.\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    \n",
    "    # Convert city to lowercase for dictionary lookup.\n",
    "    city = destination_city.lower()\n",
    "    \n",
    "    # Attempt to fetch the ticket price from the predefined dictionary; default to \"Unknown\" if not found.\n",
    "    price = ticket_prices.get(city, \"Unknown\")\n",
    "    \n",
    "    # Create a response string to be returned.\n",
    "    response_str = f'The price for {destination_city} is {price}'\n",
    "    return price, response_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee4b4c5-6d60-457c-a8af-0b0f3691b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Tool Definition for get_ticket_price\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# This dictionary defines the metadata for the 'get_ticket_price' function (tool).\n",
    "# The assistant can call this function when it needs to know the ticket price.\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": (\n",
    "        \"Get the price of a return ticket to the destination city. \"\n",
    "        \"Call this whenever you need to know the ticket price, \"\n",
    "        \"for example when a customer asks 'How much is a ticket to this city?'\"\n",
    "    ),\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8766d28-e28b-4eaa-8039-1ca59262c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Flight Booking Function\n",
    "# ---------------------------------------------------------------------------------------\n",
    "def book_flight(origin, destination, date):\n",
    "    \"\"\"\n",
    "    Books a flight by writing flight details to a .txt file named after the given date.\n",
    "\n",
    "    Args:\n",
    "        origin (str): The departure city for the flight.\n",
    "        destination (str): The arrival city for the flight.\n",
    "        date (str): The date of the flight in YYYY-MM-DD format.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - (str) The destination city\n",
    "            - (str) The origin city\n",
    "            - (str) The date of the flight\n",
    "            - (str) A confirmation string\n",
    "    \"\"\"\n",
    "    # Create or overwrite a text file named with the flight date.\n",
    "    f = open(f\"{date}.txt\", \"w\")\n",
    "    # Write flight details into that file.\n",
    "    f.write(f\"{origin}, {destination}, {date}\")\n",
    "    f.close()\n",
    "    # Provide a simple confirmation message.\n",
    "    response_str = f\"The flight for {destination} from {origin} on {date} is booked.\"\n",
    "    return destination, origin, date, response_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a21cecef-f80d-4dc7-af17-7eacb9c5f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Tool Definition for book_flight\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# This dictionary defines the metadata for the 'book_flight' function (tool).\n",
    "# The assistant can call this function to record flight booking details in a .txt file.\n",
    "book_flight_function = {\n",
    "    \"name\": \"book_flight\",\n",
    "    \"description\": (\n",
    "        \"Books the flight by writing down the flight details in a .txt file. \"\n",
    "        \"Call this whenever the user decides to book a flight and provides \"\n",
    "        \"the information about the flight destination, flight origin, and flight date.\"\n",
    "    ),\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"origin\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel from\",\n",
    "            },\n",
    "            \"destination\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\"\n",
    "            },\n",
    "            \"date\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The date of the flight in YYYY-MM-DD format\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"origin\", \"destination\", \"date\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fcc5df6-9024-4152-bb5f-3dae0e61a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Tools Collection\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# A list of available tool definitions that the model can invoke.\n",
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": book_flight_function},\n",
    "    {\"type\": \"function\", \"function\": price_function}\n",
    "]\n",
    "\n",
    "def call_function(name, args):\n",
    "    \"\"\"\n",
    "    Calls the appropriate function (tool) based on the provided name and arguments.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the function to call.\n",
    "        args (dict): The arguments for the function.\n",
    "\n",
    "    Returns:\n",
    "        Any: The return value of the called function.\n",
    "    \"\"\"\n",
    "    # Call book_flight if the name matches.\n",
    "    if name == \"book_flight\":\n",
    "        return book_flight(**args)\n",
    "    # Call get_ticket_price if the name matches.\n",
    "    if name == \"get_ticket_price\":\n",
    "        return get_ticket_price(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d755be6-46ca-4a63-af03-b179891d617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Chat Function (Legacy)\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# NOTE: This function is superseded by the \"new chat function\" below but is kept here \n",
    "# for reference/compatibility. \n",
    "def chat(message, history):\n",
    "    \"\"\"\n",
    "    Original chat function that takes a user message and conversation history, \n",
    "    passes them to the OpenAI model, and returns the assistant's response.\n",
    "    If the model invokes a tool, calls the relevant function and re-calls the model.\n",
    "    \n",
    "    Args:\n",
    "        message (str): The latest user message.\n",
    "        history (list): A list of previous messages in the conversation, \n",
    "                        where each message is a dict with 'role' and 'content'.\n",
    "    \n",
    "    Returns:\n",
    "        str: The assistant's response message as plain text.\n",
    "    \"\"\"\n",
    "    # Combine system message, conversation history, and user message.\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    # Get initial response from the model, providing tools so it can decide to call them.\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    print(response.choices[0].message.content)\n",
    "    \n",
    "    # If the model's finish_reason indicates a tool call, handle tool invocation.\n",
    "    if response.choices[0].finish_reason == \"tool_calls\":\n",
    "        messages.append(response.choices[0].message)\n",
    "        \n",
    "        for tool_call in response.choices[0].message.tool_calls:\n",
    "            # Extract the function name and arguments from the tool call.\n",
    "            name = tool_call.function.name\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "            # Call the corresponding tool function with the parsed arguments.\n",
    "            result = call_function(name, args)\n",
    "            \n",
    "            # Append the tool's result into the conversation as a 'tool' role message.\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": str(result)\n",
    "            })\n",
    "            print(messages)\n",
    "            # Re-call the model with the updated messages after tool execution.\n",
    "            response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    \n",
    "    # Return the final assistant response.\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92241148-d2be-4497-b6ac-53705fe092e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Anthropic Claude Setup\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Get the Anthropic API key from environment variables.\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "# Create an instance of the Anthropic client.\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "# System message for translation requests to Claude.\n",
    "translation_system_message = \"Translate the sequence into Russian language and return only the translation\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26f9427a-28cc-4e7d-8a42-b62cd9c572f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# New chat function (Updated)\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# This new function has similar logic to the old 'chat', but it is consolidated\n",
    "# and includes clearer variable naming and logic structure.\n",
    "\n",
    "def chat(message, history):\n",
    "    \"\"\"\n",
    "    New chat function that appends the user's message to history, \n",
    "    calls the OpenAI model, checks for any tool calls, \n",
    "    executes those tool calls if needed, and returns the final response.\n",
    "\n",
    "    Args:\n",
    "        message (str): The latest user message to add to the conversation.\n",
    "        history (list): The conversation history, \n",
    "                        as a list of dicts with 'role' and 'content'.\n",
    "\n",
    "    Returns:\n",
    "        str: The assistant's final message content after any tool calls.\n",
    "    \"\"\"\n",
    "    # Prepare the conversation for the model by including the system message at the start.\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    # Create a model completion request.\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    # print(\"Assistant:\", response.choices[0].message.content)\n",
    "    \n",
    "    # If the model indicates it wants to call a tool:\n",
    "    if response.choices[0].finish_reason == \"tool_calls\":\n",
    "        # Append the assistant's tool call message to the conversation.\n",
    "        messages.append(response.choices[0].message)\n",
    "        \n",
    "        # Process each tool call\n",
    "        for tool_call in response.choices[0].message.tool_calls:\n",
    "            # Get the function name and arguments from the tool call.\n",
    "            name = tool_call.function.name\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            # Execute the function locally.\n",
    "            result = call_function(name, args)\n",
    "            \n",
    "            # Append the tool's result as a message with 'tool' role.\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": str(result)\n",
    "            })\n",
    "            \n",
    "            # Call the model again with the new conversation state (including the tool response).\n",
    "            response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    \n",
    "    # Return the final content from the model.\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bbbbae9-fdf3-4672-b481-890dd5b636cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Translation Function for the Right Chat Window\n",
    "# ---------------------------------------------------------------------------------------\n",
    "def translation(message, history):\n",
    "    \"\"\"\n",
    "    Given a new message and some conversation history, \n",
    "    send a request to the Claude translation endpoint \n",
    "    to translate the text into Russian.\n",
    "\n",
    "    Args:\n",
    "        message (str): The new message to be translated.\n",
    "        history (list): The conversation history for context (if needed).\n",
    "\n",
    "    Returns:\n",
    "        str: The translated text.\n",
    "    \"\"\"\n",
    "    # If there is prior history, filter out unnecessary fields.\n",
    "    # This is done to keep only role and content in the messages we pass.\n",
    "    if history:\n",
    "        filtered_history = [{'role': msg['role'], 'content': msg['content']} \n",
    "                            for msg in history if 'role' in msg and 'content' in msg]\n",
    "        messages = filtered_history + [{\"role\": \"user\", \"content\": message}]\n",
    "    else:\n",
    "        messages = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    # Make a request to Claude's API, using a system prompt instructing it to translate the text.\n",
    "    response = claude.messages.create(\n",
    "        model=\"claude-3-5-sonnet-latest\",\n",
    "        max_tokens=200,\n",
    "        system=translation_system_message,\n",
    "        messages=messages\n",
    "    )\n",
    "    # The response returns a list of message objects in 'content',\n",
    "    # but we're interested in the text of the first one only.\n",
    "    return response.content[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75f1c4fd-7853-4323-8ee4-24f7c33f5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Helper for the Left Chat Interface\n",
    "# ---------------------------------------------------------------------------------------\n",
    "def do_chat(user_message, chat_history):\n",
    "    \"\"\"\n",
    "    Helper function for the left chat interface that:\n",
    "    1) Appends the user's message to the history.\n",
    "    2) Calls the main 'chat' function to get the assistant's response.\n",
    "    3) Appends the assistant's response to the history.\n",
    "    4) Returns an empty string (to clear the user textbox) and the updated history.\n",
    "\n",
    "    Args:\n",
    "        user_message (str): The user's latest input.\n",
    "        chat_history (list): The ongoing conversation history.\n",
    "\n",
    "    Returns:\n",
    "        tuple: \n",
    "            (str) An empty string to clear the text input in the UI.\n",
    "            (list) The updated chat history.\n",
    "    \"\"\"\n",
    "    # Call the main chat function to get the assistant's response.\n",
    "    response = chat(user_message, chat_history)\n",
    "    # Append the user and assistant messages to the conversation history.\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "    # Return a tuple: the first element clears the input box, the second updates the displayed history.\n",
    "    return \"\", chat_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f58c837-aa1b-48d3-b27c-c79d098fa245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Helper for the Right Chat Interface\n",
    "# ---------------------------------------------------------------------------------------\n",
    "def do_translation(chat_history, translation_history):\n",
    "    \"\"\"\n",
    "    Takes the entire conversation from the left side and translates \n",
    "    both user and assistant messages using the translation function.\n",
    "\n",
    "    Args:\n",
    "        chat_history (list): The conversation from the left chat, \n",
    "                             each message is a dict with keys 'role' and 'content'.\n",
    "        translation_history (list): The conversation for the right chat, \n",
    "                                    which we will update with translated text.\n",
    "\n",
    "    Returns:\n",
    "        list: A new conversation history of translated messages \n",
    "              (each with 'role' and 'content').\n",
    "    \"\"\"\n",
    "    translated_history = []\n",
    "\n",
    "    # Translate each message in the left chat, preserving the role.\n",
    "    for msg in chat_history:\n",
    "        # Translate the content to Russian (as instructed in translation_system_message).\n",
    "        translated_text = translation(msg[\"content\"], [])\n",
    "        translated_history.append({\"role\": msg[\"role\"], \"content\": translated_text})\n",
    "\n",
    "    # Return the fully translated conversation.\n",
    "    return translated_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d0fce9c-f7a7-4600-86e4-92e11a13ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Audio Transcription\n",
    "# ---------------------------------------------------------------------------------------\n",
    "def transcribe(audio):\n",
    "    \"\"\"\n",
    "    Transcribes an audio file using OpenAI's Whisper model.\n",
    "\n",
    "    Args:\n",
    "        audio (str): The file path to the audio file.\n",
    "\n",
    "    Returns:\n",
    "        str: The transcribed text, or an error message if the transcription fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the audio file in binary read mode.\n",
    "        audio_file = open(audio, 'rb')\n",
    "        # Use OpenAI's Whisper to create a text transcription.\n",
    "        response = openai.audio.translations.create(model=\"whisper-1\", file=audio_file)\n",
    "        \n",
    "        # Depending on how OpenAI returns the result, handle it:\n",
    "        if hasattr(response, 'text'):\n",
    "            return response.text\n",
    "        if isinstance(response, dict) and 'text' in response:\n",
    "            return response['text']\n",
    "        elif isinstance(response, str):\n",
    "            return response\n",
    "        else:\n",
    "            return f\"Error: Unexpected response format: {response}\"\n",
    "    except Exception as e:\n",
    "        # Catch and return any errors.\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def record_and_send(audio, chat_history):\n",
    "    \"\"\"\n",
    "    A function used by the UI to record audio, transcribe it, \n",
    "    and then pass the transcription to the do_chat function.\n",
    "\n",
    "    Args:\n",
    "        audio (str): The file path to the recorded audio file.\n",
    "        chat_history (list): The current conversation history of the chat.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - (str) An empty string to clear the text input in the UI.\n",
    "            - (list) The updated chat history with the transcription appended.\n",
    "    \"\"\"\n",
    "    # Convert the audio to text.\n",
    "    text = transcribe(audio)\n",
    "    # Pass the text to the do_chat function, which returns the updated chat history.\n",
    "    return do_chat(text, chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa60f4b-5eb5-4043-9586-cac10486bc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! How can I assist you today?\n",
      "Assistant: Sure! Please provide the origin city, destination city, and the date of the flight in YYYY-MM-DD format.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Gradio UI\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Build the Gradio app with two Chatbots (left and right) and an audio recorder.\n",
    "with gr.Blocks() as demo:\n",
    "    # Create two chatbots side by side: \n",
    "    # Left is the AI Assistant, right is the translated version.\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(label=\"AI Assistant (Left)\", height=500, type=\"messages\")\n",
    "        translator_chatbot = gr.Chatbot(label=\"Translated Output (Right)\", height=500, type=\"messages\")\n",
    "    \n",
    "    # Create a row containing a text box and an audio recording button.\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Enter your message:\", placeholder=\"Type your message or use the mic\")\n",
    "        record_button = gr.Audio(type=\"filepath\", label=\"ðŸŽ¤\", elem_id=\"small-record-button\", interactive=True)\n",
    "    \n",
    "    # Create a row with a clear button to reset both chat windows.\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    # When an audio file is recorded, call record_and_send(...). \n",
    "    # The outputs from record_and_send go to (entry, chatbot). \n",
    "    # Then chain to do_translation(...), which updates translator_chatbot.\n",
    "    record_button.change(record_and_send, inputs=[record_button, chatbot], outputs=[entry, chatbot]) \\\n",
    "                 .then(fn=do_translation, inputs=[chatbot, translator_chatbot], outputs=translator_chatbot)\n",
    "\n",
    "    # When the user submits text, call do_chat(...). \n",
    "    # Outputs go to (entry, chatbot). Then chain to do_translation(...).\n",
    "    entry.submit(fn=do_chat, inputs=[entry, chatbot], outputs=[entry, chatbot]) \\\n",
    "         .then(fn=do_translation, inputs=[chatbot, translator_chatbot], outputs=translator_chatbot)\n",
    "\n",
    "    # Clear button resets both chatbots' histories to empty lists.\n",
    "    clear.click(fn=lambda: [], inputs=None, outputs=[chatbot, translator_chatbot], queue=False)\n",
    "\n",
    "# Launch the Gradio interface in the browser with debug mode enabled.\n",
    "demo.launch(inbrowser=False, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc5e527-5cc3-40e0-b644-66c39e4a0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# Alternate Transcribe & Interface\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# The code below is an alternative approach to audio transcription \n",
    "# and demonstration of a separate Gradio interface.\n",
    "\n",
    "def transcribe(audio):\n",
    "    \"\"\"\n",
    "    Alternative transcription function that uses OpenAI's Whisper model\n",
    "    to convert speech audio files to text.\n",
    "\n",
    "    Args:\n",
    "        audio (str): The file path to the audio file.\n",
    "\n",
    "    Returns:\n",
    "        str: The transcribed text or an error message if something goes wrong.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the audio file in binary mode for reading.\n",
    "        audio_file = open(audio, 'rb')\n",
    "        # Call the Whisper API specifying the response format as plain text.\n",
    "        response = openai.audio.transcriptions.create(\n",
    "            model=\"whisper-1\", \n",
    "            file=audio_file, \n",
    "            response_format=\"text\"\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# A variable to store the last recorded audio (unused globally in this code, but provided for demonstration).\n",
    "recorded_audio = None\n",
    "\n",
    "def record_and_transcribe(audio):\n",
    "    \"\"\"\n",
    "    Records audio from the user, then uses the alternative transcribe function.\n",
    "\n",
    "    Args:\n",
    "        audio (str): The file path to the recorded audio file.\n",
    "\n",
    "    Returns:\n",
    "        str: The transcribed text from the audio.\n",
    "    \"\"\"\n",
    "    global recorded_audio\n",
    "    recorded_audio = audio\n",
    "    return transcribe(audio)\n",
    "\n",
    "# Create a minimal Gradio interface just for speech-to-text transcription.\n",
    "iface = gr.Interface(\n",
    "    fn=record_and_transcribe,\n",
    "    inputs=gr.Audio(type=\"filepath\", label=\"Record your voice\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Speech-to-Text Transcription\",\n",
    "    description=\"Record your voice and get a text transcription.\",\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "# Launch the second (minimal) interface.\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c46aa1-4143-4d2d-99ec-5950d8a02b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##############\n",
    "# Your new chat function\n",
    "##############\n",
    "def chat(message, history):\n",
    "    \"\"\"\n",
    "    New chat function that appends the user message to history, \n",
    "    calls the model, checks for tool_calls, and (if needed) \n",
    "    calls the relevant tools.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    print(\"Assistant:\", response.choices[0].message.content)\n",
    "    \n",
    "    # If the assistant invoked a tool, handle it\n",
    "    if response.choices[0].finish_reason == \"tool_calls\":\n",
    "        # The assistant's tool-call request is appended\n",
    "        messages.append(response.choices[0].message)\n",
    "        for tool_call in response.choices[0].message.tool_calls:\n",
    "            name = tool_call.function.name\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            result = call_function(name, args)\n",
    "            \n",
    "            # Add the tool's response\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": str(result)\n",
    "            })\n",
    "            # Make another request with the new messages\n",
    "            response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    \n",
    "    # Finally, return just the string content of the modelâ€™s last response\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "##############\n",
    "# Translation function for the right chat window\n",
    "##############\n",
    "def translation(message, history):\n",
    "    \"\"\"\n",
    "    Given a new message and some conversation history, \n",
    "    call your Claude translation endpoint.\n",
    "    \"\"\"\n",
    "    if history:\n",
    "        # Filter out unnecessary fields from history\n",
    "        filtered_history = [{'role': msg['role'], 'content': msg['content']} for msg in history if 'role' in msg and 'content' in msg]\n",
    "        messages = filtered_history + [{\"role\": \"user\", \"content\": message}]\n",
    "    else:\n",
    "        # If no prior history, just pass this single message\n",
    "        messages = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    # Example usage of the Claude API\n",
    "    response = claude.messages.create(\n",
    "        model=\"claude-3-5-sonnet-latest\",\n",
    "        max_tokens=200,\n",
    "        system=translation_system_message,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.content[0].text  # Correct way to access the response text\n",
    "\n",
    "\n",
    "##############\n",
    "# Helper for the left chat interface\n",
    "##############\n",
    "def do_chat(user_message, chat_history):\n",
    "    \"\"\"\n",
    "    1) Appends user message to the left chat's history\n",
    "    2) Invokes chat(...) to get the assistant's reply\n",
    "    3) Returns updated chat history for display\n",
    "    \"\"\"\n",
    "    # The `chat_history` parameter here is your existing list of dicts \n",
    "    # (e.g. [{\"role\":\"user\", \"content\":...}, {\"role\":\"assistant\", \"content\":...}, ...])\n",
    "    response = chat(user_message, chat_history)\n",
    "    # Append user and assistant messages to the conversation\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "    # Return two things: (1) empty string to clear the textbox, (2) the updated chat history\n",
    "    return \"\", chat_history\n",
    "\n",
    "##############\n",
    "# Helper for the right chat interface\n",
    "##############\n",
    "def do_translation(chat_history, translation_history):\n",
    "    \"\"\"\n",
    "    Takes the entire conversation from the left (chat_history).\n",
    "    Translates both user and assistant messages, maintaining the same order.\n",
    "    \"\"\"\n",
    "    translated_history = []\n",
    "\n",
    "    for msg in chat_history:\n",
    "        # Translate both user and assistant messages\n",
    "        translated_text = translation(msg[\"content\"], [])\n",
    "        # Append the translated message while preserving the role\n",
    "        translated_history.append({\"role\": msg[\"role\"], \"content\": translated_text})\n",
    "\n",
    "    return translated_history\n",
    "\n",
    "def transcribe(audio):\n",
    "    try:\n",
    "        audio_file = open(audio, 'rb')\n",
    "        response = openai.audio.translations.create(model=\"whisper-1\", file=audio_file)\n",
    "        if hasattr(response, 'text'):\n",
    "            return response.text\n",
    "        if isinstance(response, dict) and 'text' in response:\n",
    "            return response['text']\n",
    "        elif isinstance(response, str):\n",
    "            return response\n",
    "        else:\n",
    "            return f\"Error: Unexpected response format: {response}\"    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"    \n",
    "\n",
    "\n",
    "\n",
    "def record_and_send(audio, chat_history):\n",
    "    text = transcribe(audio)\n",
    "    return do_chat(text, chat_history)\n",
    "\n",
    "##############\n",
    "# Gradio UI\n",
    "##############\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(label=\"AI Assistant (Left)\", height=500, type=\"messages\")\n",
    "        translator_chatbot = gr.Chatbot(label=\"Translated Output (Right)\", height=500, type=\"messages\")\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Enter your message:\", placeholder=\"Type your message or use the mic\")\n",
    "        record_button = gr.Audio(type=\"filepath\", label=\"ðŸŽ¤\", elem_id=\"small-record-button\", interactive=True)\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    record_button.change(record_and_send, inputs=[record_button, chatbot], outputs=[entry, chatbot]).then(fn=do_translation, inputs=[chatbot, translator_chatbot], outputs=translator_chatbot)\n",
    "\n",
    "    entry.submit(fn=do_chat, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(fn=do_translation, inputs=[chatbot, translator_chatbot], outputs=translator_chatbot)\n",
    "\n",
    "    clear.click(fn=lambda: [], inputs=None, outputs=[chatbot, translator_chatbot], queue=False)\n",
    "\n",
    "demo.launch(inbrowser=False, debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83ecdcd7-a182-4ff6-89fb-d5e70584bdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transcribe(audio):\n",
    "    try:\n",
    "        # Transcribe the audio using OpenAI's Whisper API\n",
    "        audio_file = open(audio, 'rb')\n",
    "        response = openai.audio.transcriptions.create(\n",
    "            model=\"whisper-1\", \n",
    "            file=audio_file, \n",
    "            response_format=\"text\"\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "recorded_audio = None\n",
    "\n",
    "def record_and_transcribe(audio):\n",
    "    global recorded_audio\n",
    "    recorded_audio = audio\n",
    "    return transcribe(audio)\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=record_and_transcribe,\n",
    "    inputs=gr.Audio(type=\"filepath\", label=\"Record your voice\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Speech-to-Text Transcription\",\n",
    "    description=\"Record your voice and get a text transcription.\",\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904933b7-0961-44a8-ad18-d3c5014c301c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
